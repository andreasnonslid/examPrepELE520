{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy as sym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes decision theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminant functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case I\n",
    "\n",
    "Given a diagonal covariance matrix:\n",
    "$$\\Sigma=\\sigma^2 I$$\n",
    "\n",
    "The discriminant function can be calculated as:\n",
    "\n",
    "$$g_i (x)=-\\frac{1}{2\\sigma^2}||x-\\mu_i||^2 + ln(P(\\omega_i))$$\n",
    "\n",
    "Furthermore, if the priors ($P(\\omega_i)$) are equal, it simplifies to:\n",
    "\n",
    "$$g_i (x)=-\\frac{1}{2\\sigma ^2}||x-\\mu_i||^2$$\n",
    "\n",
    "A Alternative representation is:\n",
    "\n",
    "$$g_i=\\theta_i^Tx + \\theta_{i0} $$\n",
    "\n",
    "With:\n",
    "\n",
    "$$\\theta_i = \\frac{1}{\\sigma^2}\\mu_i$$\n",
    "$$\\theta_{i0} = -\\frac{1}{2\\sigma^2}\\mu_i^T\\mu_i +ln(P(\\omega_i))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}\\frac{- \\left(\\mu_{1} - x_{1}\\right)^{2} - \\left(\\mu_{2} - x_{2}\\right)^{2}}{2 \\sigma^{2}}\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([[(-(\\mu_1 - x_1)**2 - (\\mu_2 - x_2)**2)/(2*\\sigma**2)]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pi = sym.symbols('P(\\omega_i)')\n",
    "\n",
    "x1, x2 = sym.symbols('x_1, x_2')\n",
    "sigma = sym.symbols('\\sigma')\n",
    "mu1, mu2 = sym.symbols('\\mu_1, \\mu_2')\n",
    "x = sym.Matrix([x1, x2])\n",
    "mu = sym.Matrix([mu1, mu2])\n",
    "\n",
    "# sigma = 1.5\n",
    "# mu = sym.Matrix([3,2])\n",
    "\n",
    "g = (-1/(2*(sigma**2)))*(sym.transpose(x-mu)*(x-mu)) + sym.Matrix([sym.log(Pi)])\n",
    "\n",
    "g = (-1/(2*(sigma**2)))*(sym.transpose(x-mu)*(x-mu))\n",
    "sym.simplify(g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case II\n",
    "\n",
    "Given a *symmetrical* $\\Sigma_i = \\Sigma$:\n",
    "$$\n",
    "\\Sigma=\n",
    "\\left(\\begin{array}{cc} \n",
    "\\sigma_{1} ^2 & . & \\sigma_{1,l}\\\\\n",
    ". & . & .\\\\\n",
    "\\sigma_{1,l} & . & \\sigma_{l} ^2\n",
    "\\end{array}\\right)\n",
    "$$ \n",
    "\n",
    "The discriminant function can be calculated as:\n",
    "\n",
    "$$g_i=\\frac{-1}{2}(x-\\mu)^T \\Sigma^{-1} (x-\\mu) + ln(P(\\omega_i))$$\n",
    "\n",
    "Furthermore, if the priors ($P(\\omega_i)$) are equal, it simplifies to:\n",
    "\n",
    "$$g_i=\\frac{-1}{2}(x-\\mu)^T \\Sigma^{-1} (x-\\mu)$$\n",
    "\n",
    "A Alternative representation is:\n",
    "\n",
    "$$g_i=\\theta_i^Tx + \\theta_{i0} $$\n",
    "\n",
    "With:\n",
    "\n",
    "$$\\theta_i = \\Sigma^{-1}\\mu_i$$\n",
    "$$\\theta_{i0} = -\\frac{1}{2}\\mu_i^T\\Sigma^{-1}\\mu_i+ln(P(\\omega_i))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}\\frac{0.5 \\left(\\left(\\mu_{1} - x_{1}\\right) \\left(\\sigma_{21} \\left(\\mu_{2} - x_{2}\\right) - \\sigma_{22} \\left(\\mu_{1} - x_{1}\\right)\\right) - \\left(\\mu_{2} - x_{2}\\right) \\left(\\sigma_{11} \\left(\\mu_{2} - x_{2}\\right) - \\sigma_{12} \\left(\\mu_{1} - x_{1}\\right)\\right)\\right)}{\\sigma_{11} \\sigma_{22} - \\sigma_{12} \\sigma_{21}}\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([[0.5*((\\mu_1 - x_1)*(\\sigma_21*(\\mu_2 - x_2) - \\sigma_22*(\\mu_1 - x_1)) - (\\mu_2 - x_2)*(\\sigma_11*(\\mu_2 - x_2) - \\sigma_12*(\\mu_1 - x_1)))/(\\sigma_11*\\sigma_22 - \\sigma_12*\\sigma_21)]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pi = sym.symbols('P(\\omega_i)')\n",
    "\n",
    "x1, x2 = sym.symbols('x_1, x_2')\n",
    "s11, s12, s21, s22 = sym.symbols('\\sigma_11, \\sigma_12, \\sigma_21, \\sigma_22')\n",
    "mu1, mu2 = sym.symbols('\\mu_1, \\mu_2')\n",
    "x = sym.Matrix([x1, x2])\n",
    "sigma = sym.Matrix([[s11,s12],[s21,s22]])\n",
    "mu = sym.Matrix([mu1, mu2])\n",
    "\n",
    "# sigma = sym.Matrix([[1,2],[3,4]])\n",
    "# mu = sym.Matrix([3,2])\n",
    "\n",
    "g = (-1/(2))*(sym.transpose(x-mu)* sigma**-1 *(x-mu)) + sym.Matrix([sym.log(Pi)])\n",
    "\n",
    "g = (-1/(2))*(sym.transpose(x-mu)* sigma**-1 *(x-mu))\n",
    "sym.simplify(g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case III\n",
    "\n",
    "Given a *arbitrary* $\\Sigma_i$ (Class dependent),\n",
    "\n",
    "The discriminant function can be calculated as:\n",
    "\n",
    "$$g_i=\\frac{-1}{2}(x-\\mu)^T \\Sigma_i ^{-1} (x-\\mu) - \\frac{1}{2}ln(|\\Sigma_i|) + ln(P(\\omega_i))$$\n",
    "\n",
    "Furthermore, if the priors ($P(\\omega_i)$) are equal, it simplifies to:\n",
    "\n",
    "$$g_i=\\frac{-1}{2}(x-\\mu)^T \\Sigma^{-1} (x-\\mu) - \\frac{1}{2}ln(|\\Sigma_i|)$$\n",
    "\n",
    "A Alternative representation is:\n",
    "\n",
    "$$g_i= x^T\\Theta_ix + \\theta_i^Tx + \\theta_{i0} $$\n",
    "\n",
    "With:\n",
    "\n",
    "$$\\Theta_i = -\\frac{1}{2}\\Sigma_i^{-1}$$\n",
    "$$\\theta_i = \\Sigma^{-1}\\mu_i$$\n",
    "$$\\theta_{i0} = -\\frac{1}{2}\\mu_i^T\\Sigma^{-1}\\mu_i- \\frac{1}{2}ln(|\\Sigma_i|) +ln(P(\\omega_i))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}\\frac{0.5 \\left(\\left(\\mu_{1} - x_{1}\\right) \\left(\\sigma_{21} \\left(\\mu_{2} - x_{2}\\right) - \\sigma_{22} \\left(\\mu_{1} - x_{1}\\right)\\right) - \\left(\\mu_{2} - x_{2}\\right) \\left(\\sigma_{11} \\left(\\mu_{2} - x_{2}\\right) - \\sigma_{12} \\left(\\mu_{1} - x_{1}\\right)\\right) - \\left(\\sigma_{11} \\sigma_{22} - \\sigma_{12} \\sigma_{21}\\right) \\log{\\left(\\sigma_{11} \\sigma_{22} - \\sigma_{12} \\sigma_{21} \\right)}\\right)}{\\sigma_{11} \\sigma_{22} - \\sigma_{12} \\sigma_{21}}\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([[0.5*((\\mu_1 - x_1)*(\\sigma_21*(\\mu_2 - x_2) - \\sigma_22*(\\mu_1 - x_1)) - (\\mu_2 - x_2)*(\\sigma_11*(\\mu_2 - x_2) - \\sigma_12*(\\mu_1 - x_1)) - (\\sigma_11*\\sigma_22 - \\sigma_12*\\sigma_21)*log(\\sigma_11*\\sigma_22 - \\sigma_12*\\sigma_21))/(\\sigma_11*\\sigma_22 - \\sigma_12*\\sigma_21)]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pi = sym.symbols('P(\\omega_i)')\n",
    "\n",
    "x1, x2 = sym.symbols('x_1, x_2')\n",
    "s11, s12, s21, s22 = sym.symbols('\\sigma_11, \\sigma_12, \\sigma_21, \\sigma_22')\n",
    "mu1, mu2 = sym.symbols('\\mu_1, \\mu_2')\n",
    "x = sym.Matrix([x1, x2])\n",
    "sigma = sym.Matrix([[s11,s12],[s21,s22]])\n",
    "mu = sym.Matrix([mu1, mu2])\n",
    "\n",
    "# sigma = sym.Matrix([[1,2],[3,4]])\n",
    "# mu = sym.Matrix([3,2])\n",
    "\n",
    "g = (-1/(2))*(sym.transpose(x-mu)* sigma**-1 *(x-mu)) - sym.Matrix([(1/2)*sym.log(sym.det(sigma))]) + sym.Matrix([sym.log(Pi)])\n",
    "\n",
    "g = (-1/(2))*(sym.transpose(x-mu)* sigma**-1 *(x-mu)) - sym.Matrix([(1/2)*sym.log(sym.det(sigma))])\n",
    "sym.simplify(g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with exam 2021 version A, task 1 g-i\n",
    "\n",
    "**Case II**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma1 = sym.Matrix([[0.5,0],[0,0.5]])\n",
    "mu1 = sym.Matrix([-1.5,-1.5])\n",
    "P1 = 0.2\n",
    "\n",
    "sigma2 = sym.Matrix([[1,0],[0,0.5]])\n",
    "mu2 = sym.Matrix([1.5,1.5])\n",
    "P2 = 0.6\n",
    "\n",
    "sigma3 = sym.Matrix([[0.5,0],[0,0.5]])\n",
    "mu3 = sym.Matrix([0,0])\n",
    "P3 = 0.2\n",
    "\n",
    "g1 = (-1/(2))*(sym.transpose(x-mu1)* sigma1**-1 *(x-mu1)) + sym.Matrix([sym.log(P1)])\n",
    "g2 = (-1/(2))*(sym.transpose(x-mu2)* sigma2**-1 *(x-mu2)) + sym.Matrix([sym.log(P2)])\n",
    "g3 = (-1/(2))*(sym.transpose(x-mu3)* sigma3**-1 *(x-mu3)) + sym.Matrix([sym.log(P3)])\n",
    "# sym.expand(g1) # Verified, note: Constant wrong, probably due to rounding errors? -5.42 =|= -6.109...\n",
    "# sym.expand(g2) # Verified, note: Constant wrong, probably due to rounding errors? -3.54 =|= -3.886...\n",
    "# sym.expand(g3) # Verified, note: Constant wrong, probably due to rounding errors? -0.916 =|= -1.609..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumptions:\n",
    "\n",
    "1. The samples in $\\chi_i$ have been independently drawn from $p(x|\\omega_i)$.\n",
    "2. $p(x|\\omega_i)$ has a known type of distribution with form defined by parameters in $\\Theta_i$.\n",
    "\n",
    "From this the distribution is denoted as:\n",
    "\n",
    "$$p(x|\\omega_i,\\Theta_i)$$\n",
    "\n",
    "For gaussian distributions $\\Theta_i$ then consists of elements from $\\mu_i$ and $\\Sigma_i$.\n",
    "\n",
    "The methodology is to estimate $\\Theta_i$ from provided data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likelihood of a dataset explained by a given $\\Theta_i$:\n",
    "\n",
    "$$p(\\chi_i,\\Theta_i)=\\prod_{k=1}^N p(x_n,\\Theta_i)$$\n",
    "\n",
    "Estimate the $\\Theta$ to obtain maximum likelihood, which is done by differentiating and setting equal to 0, solving for $\\Theta$.\n",
    "\n",
    "This is much easier when using log-likelihoods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a monovariable gaussian distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\mu is: 1.0\n",
      "\\sigma is: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "dataset = np.array([0,0,1,1,2,2])\n",
    "N       = len(dataset)\n",
    "mu      = 1/N * sum(dataset)\n",
    "sigma   = 1/N * sum((dataset-mu)**2)\n",
    "print(f'\\mu is: {mu}\\n\\sigma is: {sigma}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a multivariate gaussian distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\mu_0 is: 1.0\n",
      "\\sigma_0^2 is: 0.6666666666666666\n",
      "\\mu_1 is: 2.0\n",
      "\\sigma_1^2 is: 2.6666666666666665\n",
      "\\mu_2 is: 0.2\n",
      "\\sigma_2^2 is: 0.026666666666666672\n"
     ]
    }
   ],
   "source": [
    "dataset = np.array([[0,0,1,1,2,2],[0,0,2,2,4,4],[0,0,.2,.2,.4,.4]])\n",
    "numClasses = len(dataset)\n",
    "dataLen = len(dataset[0])\n",
    "mu = np.zeros([numClasses,1])\n",
    "sigma = np.zeros([numClasses,1])\n",
    "for i, data in enumerate(dataset):\n",
    "    mu[i]      = 1/N * np.sum(data)\n",
    "    sigma[i]   = 1/N * np.dot(data-mu[i],(data-mu[i]))\n",
    "    print(f'\\mu_{i} is: {mu[i][0]}\\n\\sigma_{i}^2 is: {sigma[i][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-parametric estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to parameter estimation, non-parametric estimation doesn't assume the form distribution to be known."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regional density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear discriminant functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@TODO"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e40badb7bcb1e92d160f0b4bed5c17fe911a99e768c213b4c3307cd30d71202"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
